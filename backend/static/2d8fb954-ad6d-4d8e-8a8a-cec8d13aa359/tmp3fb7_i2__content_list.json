[
    {
        "type": "text",
        "text": "ZEP: 一种用于代理记忆的 时间知识图谱架构",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "解析AI代理的长期记忆解决方案",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Zep AI团队\nPreston Rasmussen, Pavlo Paliychuk, Travis Beauvais, Jack Ryan, Daniel Chalef ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "问题背景",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "LLM代理的记忆限制",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "大型语言模型（LLMs）的上下文窗口有限，无法有效利用长期记忆，导致对话连贯性和知识保留能力受限。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "现有RAG方法的局限性",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "传统检索增强生成（RAG）框架主要依赖静态文档检索，难以处理动态变化的信息和复杂的时间关系。",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "\\$\\textcolor{blue}{\\bullet}\\$ 企业应用的特殊需求",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "企业级应用需要从多样化来源（对话历史、业务数 据等）动态整合知识，并保持历史关系的完整性。",
        "page_idx": 1
    },
    {
        "type": "image",
        "img_path": "images/7f574a186cac1a130f22d7a6af98ef681bd328a3fd6cb9cc981076dfd1c3463b.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Zep解决方案概述",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Graphiti：时间感知知识图谱引擎",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Zep的核心组件，一个动态、时间感知的知识图谱 引擎，能够表示复杂、不断演变的世界。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "√ 动态合成多源数据",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "无缝整合非结构化对话数据和结构化业务数据，提 供全面的上下文理解。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "时间线维护",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "以非损失方式动态更新知识图谱，维护事实和关系 的有效期时间线，支持时间推理。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "生产级性能",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "专注于准确性、延迟和可扩展性，在DMR和 LongMemEval基准测试中表现优异。",
        "page_idx": 2
    },
    {
        "type": "image",
        "img_path": "images/d066b6e2a87d6e77c11df40810023d8cb8864c80c6b9cd2e31a10dac3662d2d7.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "知识图谱架构",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "三层子图结构",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "\\bullet 情景子图 (Ge)：包含原始输入数据（消息、文 本、JSON）",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "\\bullet 语义实体子图 (Gs): 表示从情景中提取的实体 及其关系",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "\\bullet 社区子图 (Gc)：表示强连接实体的集群及其高 级摘要",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "双时间模型",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "\\bullet 时间线T：事件的编年顺序",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "\\bullet 时间线T'：Zep数据摄取的事务顺序",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "人类记忆模型对应",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "模拟人类记忆系统中的情景记忆（特定事件）和语义记忆（概念关联）。",
        "page_idx": 3
    },
    {
        "type": "image",
        "img_path": "images/18af5365fcedb825528709e67ed21a5ca3de131d6054bda0184e6243cf0a0241.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "核心技术：情景处理",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "情景类型",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "\\bullet 消息：对话内容与发言者信息",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "\\bullet 文本：结构化文档内容",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "\\bullet JSON：结构化业务数据",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "时间戳处理",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "每个情景包含参考时间戳tref，用于准确提取和表 示绝对时间戳（如\"2023年6月1日\"）和相对时间戳 （如\"两周前\"、\"下周四\"）。",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "双向索引与无损存储",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "情景边(Ee)连接情景与提取的实体节点，维护双向索引以实现前向和后向遍历，确保语义信息可追溯到源头。",
        "page_idx": 4
    },
    {
        "type": "image",
        "img_path": "images/0e157bba589dd95ab5e72d2749bd578cf9cd0c618452542927e4182d5dc7784c.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "// 情景数据示例 { \"type\": \"message\", \"content\": \"我下周四要去北京出差\", \"actor\": \"用户\", \"timestamp\": \"2023-06-01T10:30:00Z\" } ",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "核心技术：实体与事实",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "实体提取与解析流程",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "提取实体",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "生成嵌入",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "实体解析 ",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "图谱整合",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "使用反思技术（reflexion）最小化幻觉并增强提取覆盖率，实体名称嵌入到1024维向量空间。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "事实提取与超边实现",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "同一事实可在不同实体间多次提取，通过超边实现 复杂多实体事实的建模，并使用相似的解析流程进 行边去重。",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "时间提取与边失效机制",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "- 四个时间戳：t'created、t'expired ∈ T（系统时间）和 t'valid、tinvalid ∈ T（事实有效期）",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "\\bullet 边失效：新边可使相关现有边失效，设置其 tinvalid为新边的tvalid ",
        "page_idx": 5
    },
    {
        "type": "image",
        "img_path": "images/47bfed2f22e096feca832a9585e4d4430e7e5c41f4028e00b175da27489e44c6.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "记忆检索系统",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "识别候选节 点和边 ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "构造(x) 生成文本上 下文",
        "page_idx": 6
    },
    {
        "type": "equation",
        "text": "$$\nf ( \\alpha ) = \\chi ( \\rho ( \\phi ( \\alpha ) ) ) = \\beta\n$$",
        "text_format": "latex",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "多种搜索方法",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "\\bullet 余弦语义相似度搜索 (\\$\\phi\\$cos)：捕获语义相似性",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "• Okapi BM25全文搜索 (φbm25)：识别词语相似性",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "\\bullet 广度优先搜索 (φbfs)：揭示上下文相似性",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "重排序策略",
        "text_level": 1,
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "\\$\\bullet\\$ RRF和MMR：传统重排序方法",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "\\$\\bullet\\$ 情景提及重排序器：基于实体/事实提及频率",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "• 节点距离重排序器：基于图距离 ",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "- 交叉编码器：使用LLM生成相关性分数",
        "page_idx": 6
    },
    {
        "type": "image",
        "img_path": "images/fbc4b021b78cfcc5f89dd8f211c5c65d697a9400cb27141a99028be5a6a006ee.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "性能评估 ",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "DMR基准测试 ",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "在Deep Memory Retrieval基准测试中，Zep达到94.8%的准确率（使用gpt-4-turbo），超过MemGPT的93.4%。",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "LongMemEval基准测试 ",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/b577355df5d9dfcff86a4ce55c36a9e0b8997967a309e9ef588a7e70f10174db.jpg",
        "img_caption": [
            "Accuracy Comparison "
        ],
        "img_footnote": [],
        "page_idx": 7
    },
    {
        "type": "image",
        "img_path": "images/aed5442ae280efab1f6082622da2f585df40a5b03861b6c84017c2caa22deaca.jpg",
        "img_caption": [
            "Latency Comparison "
        ],
        "img_footnote": [],
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "在更具挑战性的LongMemEval基准测试中，Zep使 用gpt\\-4o达到71.2%的准确率，比基线提高了 18.5%。",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "延迟改进 ",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Zep将响应延迟从基线的28.9秒减少到2.58秒，降 低了约90%，同时保持更高的准确率。",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "复 杂任务表现 ",
        "text_level": 1,
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "在复杂问题类型（如单会话偏好、多会话和时间推理）中表现出最显著的提升，特别是与更强大的模型结合时。",
        "page_idx": 7
    },
    {
        "type": "table",
        "img_path": "images/e670e3caf3e344f6a17e50fb5076e3944bac9166d0e2e7927ceb1c98c140f6bb.jpg",
        "table_caption": [],
        "table_footnote": [],
        "table_body": "\n\n<table> <thead>  <tr><th>问题类型</th><th>基线 (gpt-4o)</th><th>Zep (gpt-4o)</th><th>提升</th>  </tr> </thead> <tbody>  <tr><td>单会话偏好</td><td>20.0%</td><td>56.7%</td><td>+184%</td>  </tr>  <tr><td>时间推理</td><td>45.1%</td><td>62.4%</td><td>+38.4%</td>  </tr>  <tr><td>多会话</td><td>44.3%</td><td>57.9%</td><td>+30.7%</td>  </tr>  <tr><td>单会话用户</td><td>81.4%</td><td>92.9%</td><td>+14.1%</td>  </tr> </tbody></table>\n\n",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "应用场景与未来展望 ",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "企业级应用场景",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "客户服务代理",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "业务智能助手",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "销售支持系统",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "知识管理平台",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "研究方向",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "\\bullet 模型微调：为Graphiti提示词微调专用模型，提 高准确率并降低成本和延迟",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "\\bullet 领域本体：探索特定领域知识图谱本体在 Graphiti框架中的应用",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "\\bullet 多模态集成：扩展到图像、音频等多模态数据 的处理和记忆",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "集成可能性",
        "text_level": 1,
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "与其他GraphRAG方法（如AriGraph、",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "GraphRAG、LightRAG等）的集成，结合各自优势 创建更强大的记忆系统。",
        "page_idx": 8
    },
    {
        "type": "image",
        "img_path": "images/add2f53614eab93dcacf5071c1403a19a6b94d1367f4f11a361d5ca05ec067ef.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "总结与参考",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "核心创新点",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "Knowledge Gr ",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "时间感知知识图谱：维护事实和关系的有效期 时间线",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "三层次子图结构：情景、语义实体和社区层次",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "动态更新机制：非损失方式整合新信息",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "关键技术优势 ",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "image",
        "img_path": "images/bd292f6b2f796a4f8681ae792845c279aa7bcced0a5b7e61503c6b2a8abf19ef.jpg",
        "img_caption": [],
        "img_footnote": [],
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "• 优异的准确性：在DMR和LongMemEval基准测 试中表现卓越 ",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "\\bullet 复杂任务处理能力：在跨会话信息合成和长期 上下文维护方面表现突出",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "\\bullet 显著的延迟改进：响应时间减少约90% ",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "主要参考文献",
        "text_level": 1,
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "[1] Zep: Long-term memory for AI agents. https://www.getzep.com\n\n[2] Graphiti: Temporal knowledge graphs for agentic applications. https://github.com/getzep/graphiti\n\n[3] Packer, C. et al. Memgpt: Towards llms as operating systems, 2024.\n\n[4] Edge, D. et al. From local to global: A graph rag approach to query-focused summarization, 2024.\n\n[5] Wu, D. et al. Longmemeval: Benchmarking chat assistants on long-term interactive memory, 2024 ",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "联系方式：info@getzep.com | github.com/getzep/graphiti ",
        "page_idx": 9
    }
]