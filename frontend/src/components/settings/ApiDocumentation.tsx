/**
 * API Documentation Component
 * Displays API usage documentation with example code
 */

import React from 'react';
import { FileText, Copy, X } from 'lucide-react';
import {
  Dialog,
  DialogContent,
  DialogHeader,
  DialogTitle,
} from '@/components/ui/dialog';
import { Button } from '@/components/ui/button';
import { toast } from 'sonner';
import { useAuthStore } from '@/store/authStore';
import BlockMarkdownViewer from '@/components/markdown/BlockMarkdownViewer';
import './api-documentation.css';

interface ApiDocumentationProps {
  isOpen: boolean;
  onClose: () => void;
}

export const ApiDocumentation: React.FC<ApiDocumentationProps> = ({ isOpen, onClose }) => {
  const { token } = useAuthStore();
  
  // Generate API documentation with current user's token
  const generateDocumentation = () => {
    const baseUrl = window.location.origin;
    const tokenDisplay = token || 'YOUR_API_TOKEN';
    
    return `# MonkeyOCR WebApp API æ–‡æ¡£

## è®¤è¯

æ‰€æœ‰ API è¯·æ±‚éƒ½éœ€è¦åœ¨è¯·æ±‚å¤´ä¸­åŒ…å« JWT Tokenï¼š

\`\`\`
Authorization: Bearer ${tokenDisplay}
\`\`\`

## Python ç¤ºä¾‹ä»£ç 

### å®‰è£…ä¾èµ–

\`\`\`bash
pip install requests

# å¦‚æœéœ€è¦è‡ªåŠ¨è§£å‹åŠŸèƒ½ï¼ŒPythonå·²å†…ç½®zipfileæ¨¡å—ï¼Œæ— éœ€é¢å¤–å®‰è£…
\`\`\`

### å®Œæ•´ç¤ºä¾‹

\`\`\`python
import requests
import time
import mimetypes
import zipfile
import shutil
from pathlib import Path

class MonkeyOCRClient:
    """MonkeyOCR WebApp API å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url="${baseUrl}", token="${tokenDisplay}"):
        self.base_url = base_url.rstrip('/')
        self.token = token
        self.headers = {
            "Authorization": f"Bearer {self.token}"
        }
    
    def upload_file(self, file_path, ocr_option="basic"):
        """
        ä¸Šä¼ æ–‡ä»¶è¿›è¡Œ OCR è¯†åˆ«
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            ocr_option: OCR é€‰é¡¹ ("basic", "format", "markdown")
        
        Returns:
            ä»»åŠ¡ ID
        """
        url = f"{self.base_url}/api/upload"
        
        # è·å–æ–‡ä»¶çš„ MIME ç±»å‹
        file_path = Path(file_path)
        mime_type, _ = mimetypes.guess_type(str(file_path))
        
        # å¦‚æœæ— æ³•çŒœæµ‹ MIME ç±»å‹ï¼Œæ ¹æ®æ‰©å±•åè®¾ç½®
        if not mime_type:
            ext = file_path.suffix.lower()
            mime_map = {
                '.pdf': 'application/pdf',
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.png': 'image/png',
                '.webp': 'image/webp'
            }
            mime_type = mime_map.get(ext, 'application/octet-stream')
        
        with open(file_path, 'rb') as f:
            files = {'file': (file_path.name, f, mime_type)}
            data = {'ocr_option': ocr_option}
            
            response = requests.post(
                url, 
                files=files, 
                data=data,
                headers=self.headers
            )
        
        if response.status_code == 200:
            result = response.json()
            # API è¿”å›åŒ…è£…çš„å“åº”æ ¼å¼
            if result.get('success'):
                task_data = result.get('data', {})
                return task_data.get('id')
            else:
                raise Exception(f"APIè¿”å›å¤±è´¥: {result.get('message')}")
        else:
            raise Exception(f"ä¸Šä¼ å¤±è´¥: {response.text}")
    
    def get_task_status(self, task_id):
        """
        è·å–ä»»åŠ¡çŠ¶æ€
        
        Args:
            task_id: ä»»åŠ¡ ID
        
        Returns:
            ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
        """
        url = f"{self.base_url}/api/tasks/{task_id}/status"
        response = requests.get(url, headers=self.headers)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                return result.get('data', {})
            else:
                raise Exception(f"APIè¿”å›å¤±è´¥: {result.get('message')}")
        else:
            raise Exception(f"è·å–çŠ¶æ€å¤±è´¥: {response.text}")
    
    def get_task_result(self, task_id):
        """
        è·å–ä»»åŠ¡ç»“æœ
        
        Args:
            task_id: ä»»åŠ¡ ID
        
        Returns:
            OCR è¯†åˆ«ç»“æœ
        """
        url = f"{self.base_url}/api/tasks/{task_id}/result"
        response = requests.get(url, headers=self.headers)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                return result.get('data', {})
            else:
                raise Exception(f"APIè¿”å›å¤±è´¥: {result.get('message')}")
        else:
            raise Exception(f"è·å–ç»“æœå¤±è´¥: {response.text}")
    
    def wait_for_completion(self, task_id, timeout=300):
        """
        ç­‰å¾…ä»»åŠ¡å®Œæˆ
        
        Args:
            task_id: ä»»åŠ¡ ID
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            ä»»åŠ¡ç»“æœ
        """
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            status = self.get_task_status(task_id)
            
            if status['status'] == 'completed':
                return self.get_task_result(task_id)
            elif status['status'] == 'failed':
                raise Exception(f"ä»»åŠ¡å¤±è´¥: {status.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            time.sleep(2)  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
        
        raise TimeoutError(f"ä»»åŠ¡è¶…æ—¶: {timeout}ç§’")
    
    def process_document(self, file_path, ocr_option="markdown"):
        """
        å®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            ocr_option: OCR é€‰é¡¹
        
        Returns:
            å¤„ç†ç»“æœ
        """
        print(f"ä¸Šä¼ æ–‡ä»¶: {file_path}")
        task_id = self.upload_file(file_path, ocr_option)
        print(f"ä»»åŠ¡ID: {task_id}")
        
        print("ç­‰å¾…å¤„ç†...")
        result = self.wait_for_completion(task_id)
        
        print("å¤„ç†å®Œæˆ!")
        return result
    
    def download_result(self, download_url, output_path="result.zip"):
        """
        ä¸‹è½½OCRç»“æœæ–‡ä»¶
        
        Args:
            download_url: ä¸‹è½½é“¾æ¥
            output_path: ä¿å­˜è·¯å¾„
        
        Returns:
            ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œæ‹¼æ¥åŸºç¡€URL
            if download_url.startswith('/'):
                full_url = f"{self.base_url}{download_url}"
            else:
                full_url = download_url
            
            print(f"ä¸‹è½½æ–‡ä»¶: {full_url}")
            
            response = requests.get(full_url, headers=self.headers, stream=True)
            
            if response.status_code == 200:
                with open(output_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                print(f"æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path}")
                return True
            else:
                print(f"ä¸‹è½½å¤±è´¥ (HTTP {response.status_code}): {response.text}")
                return False
        except Exception as e:
            print(f"ä¸‹è½½é”™è¯¯: {e}")
            return False
    
    def extract_result(self, zip_path, extract_dir=None):
        """
        è§£å‹OCRç»“æœæ–‡ä»¶
        
        Args:
            zip_path: ZIPæ–‡ä»¶è·¯å¾„
            extract_dir: è§£å‹ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        
        Returns:
            è§£å‹ç›®å½•è·¯å¾„
        """
        try:
            zip_path = Path(zip_path)
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè§£å‹ç›®å½•ï¼Œä½¿ç”¨ZIPæ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
            if extract_dir is None:
                extract_dir = zip_path.stem
            
            extract_dir = Path(extract_dir)
            
            # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if extract_dir.exists():
                print(f"ç›®å½• {extract_dir} å·²å­˜åœ¨ï¼Œåˆ é™¤æ—§ç›®å½•...")
                shutil.rmtree(extract_dir)
            
            # åˆ›å»ºç›®å½•å¹¶è§£å‹
            extract_dir.mkdir(parents=True, exist_ok=True)
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            print(f"âœ… æ–‡ä»¶å·²è§£å‹åˆ°: {extract_dir}")
            
            # åˆ—å‡ºè§£å‹çš„æ–‡ä»¶
            files = list(extract_dir.rglob('*'))
            print(f"  è§£å‹æ–‡ä»¶æ•°: {len([f for f in files if f.is_file()])} ä¸ª")
            
            # æ˜¾ç¤ºä¸»è¦æ–‡ä»¶
            md_files = list(extract_dir.glob('*.md'))
            if md_files:
                print(f"  Markdownæ–‡ä»¶: {', '.join([f.name for f in md_files])}")
            
            img_files = list(extract_dir.rglob('*.png')) + list(extract_dir.rglob('*.jpg'))
            if img_files:
                print(f"  å›¾ç‰‡æ–‡ä»¶: {len(img_files)} ä¸ª")
            
            return str(extract_dir)
            
        except Exception as e:
            print(f"è§£å‹é”™è¯¯: {e}")
            return None

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = MonkeyOCRClient()
    
    # è®¾ç½®è¦å¤„ç†çš„æ–‡ä»¶
    input_file = "example.pdf"
    
    # å¤„ç†å•ä¸ªæ–‡æ¡£
    try:
        result = client.process_document(input_file)
        
        # æ‰“å°ç»“æœç»“æ„
        print(f"\\nè¿”å›çš„ç»“æœå­—æ®µ: {result.keys()}")
        
        # è·å–å„ä¸ªå­—æ®µ
        task_id = result.get('task_id')
        markdown_content = result.get('markdown_content', '')
        download_url = result.get('download_url')
        metadata = result.get('metadata', {})
        
        # ä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰ä½œä¸ºåŸºç¡€åç§°
        base_name = Path(input_file).stem
        
        # åˆ›å»ºä»¥æ–‡ä»¶åå‘½åçš„ç›®å½•
        output_dir = Path(base_name)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å…ˆä¸‹è½½å¹¶è§£å‹å®Œæ•´ç»“æœåŒ…
        if download_url:
            print(f"\\nä¸‹è½½URL: {download_url}")
            
            # ä¸‹è½½ZIPæ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
            temp_zip = f"{task_id}_result.zip" if task_id else f"{base_name}_result.zip"
            
            if client.download_result(download_url, temp_zip):
                print(f"âœ… å®Œæ•´ç»“æœå·²ä¸‹è½½")
                
                # è§£å‹åˆ°ç›®æ ‡ç›®å½•
                print(f"å¼€å§‹è§£å‹æ–‡ä»¶...")
                if client.extract_result(temp_zip, str(output_dir)):
                    print(f"âœ… æ–‡ä»¶å·²è§£å‹åˆ°: {output_dir}/")
                    
                    # åˆ é™¤ä¸´æ—¶ZIPæ–‡ä»¶
                    Path(temp_zip).unlink()
                    print(f"âœ… å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
            else:
                print("âŒ ä¸‹è½½å¤±è´¥")
        
        # ç„¶åä¿å­˜ Markdown ç»“æœï¼ˆè¿™æ ·ä¸ä¼šè¢«è§£å‹è¦†ç›–ï¼‰
        if markdown_content:
            md_filename = output_dir / f"{base_name}.md"
            with open(md_filename, "w", encoding="utf-8") as f:
                f.write(markdown_content)
            print(f"âœ… Markdownå†…å®¹å·²ä¿å­˜åˆ°: {md_filename}")
        
        # è¾“å‡ºæœ€ç»ˆç»“æœ
        print(f"\\nğŸ‰ å¤„ç†å®Œæˆï¼")
        print(f"  - ç»“æœç›®å½•: {output_dir}/")
        print(f"  - Markdownæ–‡ä»¶: {output_dir}/{base_name}.md")
        if (output_dir / "images").exists():
            print(f"  - å›¾ç‰‡æ–‡ä»¶: {output_dir}/images/")
        else:
            print("\\nâš ï¸ æœªè¯†åˆ«åˆ°æ–‡æ¡£å›¾ç‰‡ï¼Œå·²è·³è¿‡")
        
        # æ˜¾ç¤ºå…ƒæ•°æ®ä¿¡æ¯
        if metadata:
            print(f"\\nğŸ“Š æ–‡æ¡£ä¿¡æ¯:")
            for key, value in metadata.items():
                print(f"  - {key}: {value}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
\`\`\`

## API ç«¯ç‚¹è¯¦ç»†è¯´æ˜

### 1. æ–‡ä»¶ä¸Šä¼ 

**ç«¯ç‚¹**: \`POST /api/upload\`

**è¯·æ±‚å¤´**:
- \`Authorization: Bearer {token}\`

**è¯·æ±‚ä½“** (multipart/form-data):
- \`file\`: è¦ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæ”¯æŒ PDF, JPG, PNG, WEBPï¼‰
- \`ocr_option\`: OCR é€‰é¡¹
  - \`"basic"\`: åŸºç¡€è¯†åˆ«
  - \`"format"\`: ä¿ç•™æ ¼å¼
  - \`"markdown"\`: Markdown æ ¼å¼ï¼ˆæ¨èï¼‰

**å“åº”ç¤ºä¾‹**:
\`\`\`json
{
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "processing",
  "created_at": "2024-01-13T10:00:00Z"
}
\`\`\`

### 2. è·å–ä»»åŠ¡çŠ¶æ€

**ç«¯ç‚¹**: \`GET /api/tasks/{task_id}/status\`

**å“åº”ç¤ºä¾‹**:
\`\`\`json
{
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "progress": 100,
  "created_at": "2024-01-13T10:00:00Z",
  "completed_at": "2024-01-13T10:01:30Z"
}
\`\`\`

### 3. è·å–ä»»åŠ¡ç»“æœ

**ç«¯ç‚¹**: \`GET /api/tasks/{task_id}/result\`

**å“åº”ç¤ºä¾‹**:
\`\`\`json
{
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "markdown_content": "# æ–‡æ¡£æ ‡é¢˜\\n\\næ–‡æ¡£å†…å®¹...",
  "page_count": 10,
  "blocks": [
    {
      "type": "text",
      "content": "æ®µè½å†…å®¹",
      "page": 1
    }
  ]
}
\`\`\`

### 4. è·å–ä»»åŠ¡åˆ—è¡¨

**ç«¯ç‚¹**: \`GET /api/tasks\`

**æŸ¥è¯¢å‚æ•°**:
- \`limit\`: è¿”å›æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰
- \`offset\`: åç§»é‡ï¼ˆé»˜è®¤: 0ï¼‰

**å“åº”ç¤ºä¾‹**:
\`\`\`json
{
  "tasks": [
    {
      "task_id": "550e8400-e29b-41d4-a716-446655440000",
      "filename": "document.pdf",
      "status": "completed",
      "created_at": "2024-01-13T10:00:00Z"
    }
  ],
  "total": 25
}
\`\`\`

## é”™è¯¯å¤„ç†

API ä½¿ç”¨æ ‡å‡† HTTP çŠ¶æ€ç ï¼š

- \`200\`: æˆåŠŸ
- \`400\`: è¯·æ±‚å‚æ•°é”™è¯¯
- \`401\`: æœªæˆæƒï¼ˆToken æ— æ•ˆæˆ–è¿‡æœŸï¼‰
- \`404\`: èµ„æºæœªæ‰¾åˆ°
- \`429\`: è¯·æ±‚è¿‡äºé¢‘ç¹
- \`500\`: æœåŠ¡å™¨é”™è¯¯

é”™è¯¯å“åº”æ ¼å¼ï¼š
\`\`\`json
{
  "error": "é”™è¯¯ä¿¡æ¯",
  "detail": "è¯¦ç»†é”™è¯¯æè¿°"
}
\`\`\`

## æ³¨æ„äº‹é¡¹

1. **æ–‡ä»¶å¤§å°é™åˆ¶**: å•ä¸ªæ–‡ä»¶æœ€å¤§ 50MB
2. **æ”¯æŒæ ¼å¼**: PDF, JPG, PNG, WEBP
3. **å¹¶å‘é™åˆ¶**: æ¯ä¸ªç”¨æˆ·æœ€å¤š 5 ä¸ªå¹¶å‘ä»»åŠ¡
4. **Token æœ‰æ•ˆæœŸ**: 24 å°æ—¶ï¼Œè¿‡æœŸéœ€é‡æ–°ç™»å½•è·å–
5. **é€Ÿç‡é™åˆ¶**: 
   - ä¸Šä¼ : 100 æ¬¡/åˆ†é’Ÿ
   - æŸ¥è¯¢: 600 æ¬¡/åˆ†é’Ÿ

## æ›´å¤šç¤ºä¾‹

### æ‰¹é‡å¤„ç†æ–‡æ¡£ - å®Œæ•´ç¤ºä¾‹

\`\`\`python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡å¤„ç† PDF æ–‡æ¡£çš„å®Œæ•´ç¤ºä¾‹
ä½¿ç”¨æ–¹æ³•: python batch_process.py /path/to/pdfs /path/to/output
"""

import os
import sys
import time
import json
import logging
import mimetypes
import zipfile
import shutil
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('batch_process.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class MonkeyOCRClient:
    """MonkeyOCR WebApp API å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url="${baseUrl}", token="${tokenDisplay}"):
        self.base_url = base_url.rstrip('/')
        self.token = token
        self.headers = {
            "Authorization": f"Bearer {self.token}"
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
    
    def upload_file(self, file_path, ocr_option="markdown"):
        """ä¸Šä¼ æ–‡ä»¶è¿›è¡Œ OCR è¯†åˆ«"""
        url = f"{self.base_url}/api/upload"
        
        # è·å–æ–‡ä»¶çš„ MIME ç±»å‹
        file_path = Path(file_path)
        mime_type, _ = mimetypes.guess_type(str(file_path))
        
        # å¦‚æœæ— æ³•çŒœæµ‹ MIME ç±»å‹ï¼Œæ ¹æ®æ‰©å±•åè®¾ç½®
        if not mime_type:
            ext = file_path.suffix.lower()
            mime_map = {
                '.pdf': 'application/pdf',
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.png': 'image/png',
                '.webp': 'image/webp'
            }
            mime_type = mime_map.get(ext, 'application/octet-stream')
        
        with open(file_path, 'rb') as f:
            files = {'file': (file_path.name, f, mime_type)}
            data = {'ocr_option': ocr_option}
            
            response = self.session.post(url, files=files, data=data)
        
        if response.status_code == 200:
            result = response.json()
            # API è¿”å›åŒ…è£…çš„å“åº”æ ¼å¼
            if result.get('success'):
                task_data = result.get('data', {})
                return task_data.get('id')
            else:
                raise Exception(f"APIè¿”å›å¤±è´¥: {result.get('message')}")
        else:
            raise Exception(f"ä¸Šä¼ å¤±è´¥: {response.text}")
    
    def get_task_status(self, task_id):
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        url = f"{self.base_url}/api/tasks/{task_id}/status"
        response = self.session.get(url)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                return result.get('data', {})
            else:
                raise Exception(f"APIè¿”å›å¤±è´¥: {result.get('message')}")
        else:
            raise Exception(f"è·å–çŠ¶æ€å¤±è´¥: {response.text}")
    
    def get_task_result(self, task_id):
        """è·å–ä»»åŠ¡ç»“æœ"""
        url = f"{self.base_url}/api/tasks/{task_id}/result"
        response = self.session.get(url)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                return result.get('data', {})
            else:
                raise Exception(f"APIè¿”å›å¤±è´¥: {result.get('message')}")
        else:
            raise Exception(f"è·å–ç»“æœå¤±è´¥: {response.text}")
    
    def wait_for_completion(self, task_id, timeout=300):
        """ç­‰å¾…ä»»åŠ¡å®Œæˆ"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            status = self.get_task_status(task_id)
            
            if status['status'] == 'completed':
                return self.get_task_result(task_id)
            elif status['status'] == 'failed':
                raise Exception(f"ä»»åŠ¡å¤±è´¥: {status.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            time.sleep(2)
        
        raise TimeoutError(f"ä»»åŠ¡è¶…æ—¶: {timeout}ç§’")
    
    def process_document_with_retry(self, file_path, max_retries=3):
        """å¸¦é‡è¯•æœºåˆ¶çš„æ–‡æ¡£å¤„ç†"""
        for attempt in range(max_retries):
            try:
                logger.info(f"å¤„ç†æ–‡ä»¶: {file_path} (å°è¯• {attempt + 1}/{max_retries})")
                
                # ä¸Šä¼ æ–‡ä»¶
                task_id = self.upload_file(file_path)
                logger.info(f"ä»»åŠ¡ID: {task_id}")
                
                # ç­‰å¾…å¤„ç†å®Œæˆ
                result = self.wait_for_completion(task_id)
                logger.info(f"æ–‡ä»¶å¤„ç†æˆåŠŸ: {file_path}")
                return result
                
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    logger.warning(f"å¤„ç†å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•: {e}")
                    time.sleep(wait_time)
                else:
                    logger.error(f"å¤„ç†å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    raise
    
    def download_result(self, download_url, output_path):
        """ä¸‹è½½OCRç»“æœæ–‡ä»¶"""
        try:
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œæ‹¼æ¥åŸºç¡€URL
            if download_url.startswith('/'):
                full_url = f"{self.base_url}{download_url}"
            else:
                full_url = download_url
            
            response = self.session.get(full_url, stream=True)
            
            if response.status_code == 200:
                with open(output_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                return True
            else:
                logger.error(f"ä¸‹è½½å¤±è´¥ (HTTP {response.status_code})")
                return False
        except Exception as e:
            logger.error(f"ä¸‹è½½é”™è¯¯: {e}")
            return False
    
    def extract_result(self, zip_path, extract_dir):
        """è§£å‹OCRç»“æœæ–‡ä»¶"""
        try:
            zip_path = Path(zip_path)
            extract_dir = Path(extract_dir)
            
            # å¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            if extract_dir.exists():
                shutil.rmtree(extract_dir)
            
            # åˆ›å»ºç›®å½•å¹¶è§£å‹
            extract_dir.mkdir(parents=True, exist_ok=True)
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            return str(extract_dir)
            
        except Exception as e:
            logger.error(f"è§£å‹é”™è¯¯: {e}")
            return None


def process_single_file(client, file_path, output_dir):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    try:
        # å¤„ç†æ–‡æ¡£
        result = client.process_document_with_retry(file_path)
        
        # ç”ŸæˆåŸºç¡€åç§°
        base_name = Path(file_path).stem
        
        # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•
        file_output_dir = Path(output_dir) / base_name
        file_output_dir.mkdir(parents=True, exist_ok=True)
        
        # å…ˆä¸‹è½½å¹¶è§£å‹å®Œæ•´ç»“æœ
        download_url = result.get('download_url')
        if download_url:
            # ä¸‹è½½ZIPæ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
            task_id = result.get('task_id', base_name)
            temp_zip = Path(output_dir) / f"temp_{task_id}.zip"
            
            if client.download_result(download_url, str(temp_zip)):
                # è§£å‹åˆ°æ–‡ä»¶ç›®å½•
                client.extract_result(str(temp_zip), str(file_output_dir))
                logger.info(f"ç»“æœå·²è§£å‹åˆ°: {file_output_dir}")
                
                # åˆ é™¤ä¸´æ—¶ZIPæ–‡ä»¶
                temp_zip.unlink()
        
        # ç„¶åä¿å­˜ Markdown å†…å®¹ï¼ˆè¿™æ ·ä¸ä¼šè¢«è§£å‹è¦†ç›–ï¼‰
        markdown_content = result.get('markdown_content', '')
        if markdown_content:
            output_path = file_output_dir / f"{base_name}.md"
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            logger.info(f"Markdownå·²ä¿å­˜: {output_path}")
        
        # æœ€åä¿å­˜å…ƒæ•°æ®
        metadata_path = file_output_dir / "metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump({
                'task_id': result.get('task_id'),
                'processed_at': datetime.now().isoformat(),
                'source_file': str(file_path),
                'metadata': result.get('metadata', {})
            }, f, ensure_ascii=False, indent=2)
        
        return True, f"âœ… {Path(file_path).name} â†’ {file_output_dir}"
        
    except Exception as e:
        return False, f"âŒ {Path(file_path).name} å¤„ç†å¤±è´¥: {e}"


def batch_process_documents(input_dir, output_dir, max_workers=3):
    """æ‰¹é‡å¤„ç†æ–‡æ¡£ä¸»å‡½æ•°"""
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
    supported_extensions = ['.pdf', '.jpg', '.jpeg', '.png', '.webp']
    files_to_process = []
    
    for ext in supported_extensions:
        files_to_process.extend(Path(input_dir).glob(f'*{ext}'))
        files_to_process.extend(Path(input_dir).glob(f'*{ext.upper()}'))
    
    if not files_to_process:
        logger.warning(f"æœªæ‰¾åˆ°å¯å¤„ç†çš„æ–‡ä»¶åœ¨: {input_dir}")
        return
    
    logger.info(f"æ‰¾åˆ° {len(files_to_process)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = MonkeyOCRClient()
    
    # ç»Ÿè®¡ä¿¡æ¯
    success_count = 0
    failed_count = 0
    results = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {
            executor.submit(process_single_file, client, file_path, output_dir): file_path
            for file_path in files_to_process
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(futures):
            file_path = futures[future]
            success, message = future.result()
            
            if success:
                success_count += 1
            else:
                failed_count += 1
            
            results.append({
                'file': str(file_path),
                'success': success,
                'message': message
            })
            
            logger.info(message)
            logger.info(f"è¿›åº¦: {success_count + failed_count}/{len(files_to_process)}")
    
    # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
    report_path = Path(output_dir) / 'processing_report.json'
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump({
            'total_files': len(files_to_process),
            'success_count': success_count,
            'failed_count': failed_count,
            'processed_at': datetime.now().isoformat(),
            'results': results
        }, f, ensure_ascii=False, indent=2)
    
    # è¾“å‡ºæ€»ç»“
    logger.info("=" * 50)
    logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆï¼")
    logger.info(f"æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
    logger.info(f"å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶")
    logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
    logger.info(f"å¤„ç†æŠ¥å‘Š: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 3:
        print("ä½¿ç”¨æ–¹æ³•: python batch_process.py <è¾“å…¥ç›®å½•> <è¾“å‡ºç›®å½•>")
        print("ç¤ºä¾‹: python batch_process.py ./pdfs ./output")
        sys.exit(1)
    
    input_dir = sys.argv[1]
    output_dir = sys.argv[2]
    
    if not Path(input_dir).exists():
        logger.error(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        sys.exit(1)
    
    # å¼€å§‹æ‰¹é‡å¤„ç†
    start_time = time.time()
    
    try:
        batch_process_documents(input_dir, output_dir, max_workers=3)
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­å¤„ç†")
    except Exception as e:
        logger.error(f"æ‰¹é‡å¤„ç†å‡ºé”™: {e}", exc_info=True)
    finally:
        elapsed_time = time.time() - start_time
        logger.info(f"æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")


if __name__ == "__main__":
    main()
\`\`\`

### ä½¿ç”¨ç¤ºä¾‹

1. **ä¿å­˜è„šæœ¬**ï¼šå°†ä¸Šé¢çš„ä»£ç ä¿å­˜ä¸º \`batch_process.py\`

2. **å‡†å¤‡æ–‡ä»¶**ï¼šå°†è¦å¤„ç†çš„ PDFã€å›¾ç‰‡æ–‡ä»¶æ”¾åœ¨ä¸€ä¸ªç›®å½•ä¸­

3. **è¿è¡Œè„šæœ¬**ï¼š
\`\`\`bash
# å¤„ç† pdfs ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼Œè¾“å‡ºåˆ° output ç›®å½•
python batch_process.py ./pdfs ./output

# å¤„ç†ç‰¹å®šç›®å½•
python batch_process.py /Users/username/Documents/scans /Users/username/Documents/ocr_results
\`\`\`

4. **æŸ¥çœ‹ç»“æœ**ï¼š
   æ¯ä¸ªæ–‡ä»¶çš„ç»“æœä¿å­˜åœ¨ç‹¬ç«‹ç›®å½•ä¸­ï¼š
   - \`output/æ–‡ä»¶å/\` - æ–‡ä»¶çš„å®Œæ•´ç»“æœç›®å½•
     - \`æ–‡ä»¶å.md\` - Markdownå†…å®¹
     - \`images/\` - æå–çš„å›¾ç‰‡
     - \`metadata.json\` - å¤„ç†å…ƒæ•°æ®
   - \`output/processing_report.json\` - æ‰¹é‡å¤„ç†æŠ¥å‘Š
   - \`batch_process.log\` - å¤„ç†æ—¥å¿—

### é«˜çº§é…ç½®ç¤ºä¾‹

\`\`\`python
# è‡ªå®šä¹‰é…ç½®çš„æ‰¹é‡å¤„ç†
import configparser

# è¯»å–é…ç½®æ–‡ä»¶
config = configparser.ConfigParser()
config.read('config.ini')

# ä½¿ç”¨é…ç½®åˆå§‹åŒ–å®¢æˆ·ç«¯
client = MonkeyOCRClient(
    base_url=config.get('api', 'base_url'),
    token=config.get('api', 'token')
)

# è‡ªå®šä¹‰å¹¶å‘æ•°
max_workers = config.getint('processing', 'max_workers', fallback=3)

# å¼€å§‹å¤„ç†
batch_process_documents(
    input_dir=config.get('paths', 'input_dir'),
    output_dir=config.get('paths', 'output_dir'),
    max_workers=max_workers
)
\`\`\`

### é…ç½®æ–‡ä»¶ç¤ºä¾‹ (config.ini)

\`\`\`ini
[api]
base_url = ${baseUrl}
token = ${tokenDisplay}

[processing]
max_workers = 5
timeout = 600
max_retries = 3

[paths]
input_dir = ./documents
output_dir = ./ocr_results
\`\`\`
`;
  };

  const handleCopyAll = async () => {
    try {
      await navigator.clipboard.writeText(generateDocumentation());
      toast.success('æ–‡æ¡£å·²å¤åˆ¶åˆ°å‰ªè´´æ¿', { duration: 2000 });
    } catch (error) {
      toast.error('å¤åˆ¶å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨é€‰æ‹©å¤åˆ¶');
    }
  };

  return (
    <Dialog open={isOpen} onOpenChange={onClose}>
      <DialogContent className="max-w-4xl max-h-[85vh] overflow-hidden flex flex-col">
        <DialogHeader className="flex-shrink-0 pb-4 border-b">
          <div className="flex items-center justify-between">
            <DialogTitle className="flex items-center gap-2">
              <FileText className="h-5 w-5" />
              API è°ƒç”¨æ–‡æ¡£
            </DialogTitle>
            <div className="flex items-center gap-2">
              <Button
                variant="outline"
                size="sm"
                onClick={handleCopyAll}
                className="gap-2"
              >
                <Copy className="h-4 w-4" />
                å¤åˆ¶å…¨éƒ¨
              </Button>
              <Button
                variant="ghost"
                size="sm"
                onClick={onClose}
                className="h-8 w-8 p-0"
              >
                <X className="h-4 w-4" />
              </Button>
            </div>
          </div>
        </DialogHeader>
        
        <div className="flex-1 overflow-y-auto px-1">
          <BlockMarkdownViewer
            content={generateDocumentation()}
            className="api-documentation"
            fontSize={90}
          />
        </div>
      </DialogContent>
    </Dialog>
  );
};